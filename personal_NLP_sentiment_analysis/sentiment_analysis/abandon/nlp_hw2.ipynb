{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489c650a",
   "metadata": {},
   "source": [
    "Please create a function (def) called gen_senti that Tokenizes arbitrary text and compares each token with the positive and negative lexicons of each dictionary and outputs the sentiment score, S.  Positive and negative words, pw and nw, count as a score of 1 and -1 respectively for each word matched.  The total count for pw and nw are pc and nc, respectively.  Each message sentiment, S, is normalized between -1 and 1.  Any text that does not any positive AND negative words would have to be ignored, and not scored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094fd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae2ba96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define file path:\n",
    "the_path = 'C:/Users/suisx/Desktop/Mo_NLP/hw2/'\n",
    "out_path = 'C:/Users/suisx/Desktop/Mo_NLP/hw2/hw2_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8feba12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/suisx/Desktop/Mo_NLP/hw2//negative-words.txt\n",
      "C:/Users/suisx/Desktop/Mo_NLP/hw2//positive-words.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_files(path_in):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    file_list = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(path_in, topdown=False):\n",
    "        for name in files:\n",
    "            try:\n",
    "                t_path = root + \"/\" + name  #this made the file_p as the key, with format of root/file_name\n",
    "                file_p = file_clean(t_path)\n",
    "                t_p = root.split(\"/\")[-1:][0]\n",
    "                #remove the databody with no content\n",
    "                if len(file_p) > 0:\n",
    "                    file_list = file_list.append(\n",
    "                        {\"body\": file_p, \"label\": t_p}, ignore_index=True)\n",
    "            except:\n",
    "                print (t_path)\n",
    "                pass\n",
    "    return file_list\n",
    "\n",
    "the_data = read_files(the_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c57d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(str_in):\n",
    "    import re\n",
    "    tmp = re.sub(\"[^A-Za-z']+\",\" \",str_in).lower().strip().replace(\"  \", \" \")\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1258d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open files:\n",
    "def file_clean(path_in):\n",
    "    f = open(path_in, encoding=\"UTF-8\")\n",
    "    tmp = f.read()\n",
    "    f.close()\n",
    "    tmp = clean_text(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cadd60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_senti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
